You are an expert software architect. The user is providing you with the complete source code for a project, contained in a single file. Your task is to meticulously analyze the provided codebase to gain a comprehensive understanding of its structure, functionality, dependencies, and overall architecture.

A file tree is provided below to give you a high-level overview. The subsequent sections contain the full content of each file, clearly marked with "// FILE: <path>".

Your instructions are:
1.  **Analyze Thoroughly:** Read through every file to understand its purpose and how it interacts with other files.
2.  **Identify Key Components:** Pay close attention to configuration files (like package.json, pyproject.toml), entry points (like index.js, main.py), and core logic.

## Project File Tree

```
easy_file/
├── .editorconfig
├── .github
│   ├── ISSUE_TEMPLATE.md
│   └── workflows
│       └── release.yml
├── .gitignore
├── .kilocodemodes
├── .pre-commit-config.yaml
├── AGENTS.md
├── CHANGELOG.md
├── LICENSE
├── README.md
├── mypy.ini
├── pyproject.toml
├── src
│   └── easy_file
│       ├── __init__.py
│       ├── easy_file.py
│       └── py.typed
└── tests
    ├── __init__.py
    ├── conftest.py
    └── test_easy_file.py
```

---

// FILE: .editorconfig
```
# http://editorconfig.org

root = true

[*]
indent_style = space
indent_size = 4
trim_trailing_whitespace = true
insert_final_newline = true
charset = utf-8
end_of_line = lf

[*.bat]
indent_style = tab
end_of_line = crlf

[LICENSE]
insert_final_newline = false

[Makefile]
indent_style = tab

```

// FILE: .github/ISSUE_TEMPLATE.md
```
* Easy File version:
* Python version:
* Operating System:

### Description

Describe what you were trying to get done.
Tell us what happened, what went wrong, and what you expected to happen.

### What I Did

```
Paste the command(s) you ran and the output.
If there was a crash, please include the traceback here.
```

```

// FILE: .github/workflows/release.yml
```
name: Release

on:
  push:
    tags:
      - 'v*'

permissions:
  contents: write
  id-token: write  # Для trusted publishing в PyPI

jobs:
  validate:
    name: Validate release
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
      
      - name: Set up Python
        run: uv python install 3.12
      
      - name: Validate version match
        run: |
          TAG_VERSION=${GITHUB_REF#refs/tags/v}
          echo "Tag version: $TAG_VERSION"
          
          # Отримуємо версію з pyproject.toml
          PACKAGE_VERSION=$(uv run python -c "import tomllib; print(tomllib.load(open('pyproject.toml', 'rb'))['project']['version'])")
          echo "Package version: $PACKAGE_VERSION"
          
          if [ "$TAG_VERSION" != "$PACKAGE_VERSION" ]; then
            echo "❌ Version mismatch!"
            echo "Git tag: v$TAG_VERSION"
            echo "pyproject.toml: $PACKAGE_VERSION"
            exit 1
          fi
          echo "✅ Versions match!"

  build:
    name: Build distribution
    needs: validate
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
      
      - name: Set up Python
        run: uv python install 3.12
      
      - name: Build package
        run: uv build
      
      - name: Generate checksums
        run: |
          cd dist
          sha256sum * > SHA256SUMS
          cat SHA256SUMS
      
      - name: Check distribution
        run: |
          uv tool run twine check dist/*
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 5

  release:
    name: Create GitHub Release
    needs: build
    runs-on: ubuntu-latest
    
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/
      
      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          files: dist/*
          generate_release_notes: true
          draft: false
          prerelease: ${{ contains(github.ref, 'alpha') || contains(github.ref, 'beta') || contains(github.ref, 'rc') }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  publish:
    name: Publish to PyPI
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/${{ github.event.repository.name }}
    
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/
      
      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          # Використовуємо trusted publishing (без токена)
          # print-hash: true
          # verbose: true
          # Альтернативно: 
          password: ${{ secrets.PYPI_API_TOKEN }}

```

// FILE: .gitignore
```
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# dotenv
.env

# virtualenv
.venv
venv/
ENV/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/

# ruff
.ruff_cache/

# IDE settings
.vscode/

# mkdocs build dir
site/
```

// FILE: .kilocodemodes
```
customModes:
  - slug: code-reviewer
    name: Code Reviewer
    roleDefinition: |
      You are a senior software engineer conducting thorough code reviews. You focus on code quality, security, performance, and maintainability.
    groups:
      - read
      - browser
    customInstructions: |
      Provide constructive feedback on code patterns, potential bugs, security issues, and improvement opportunities. Be specific and actionable in suggestions.
    source: project
  - slug: docs-specialist
    name: Documentation Specialist
    roleDefinition: |
      You are a technical writing expert specializing in clear, comprehensive documentation. You excel at explaining complex concepts simply and creating well-structured docs.
    groups:
      - read
      - command
      - - edit
        - fileRegex: \.(md|mdx|txt|rst|adoc)$|README$|CHANGELOG$
          description: Documentation files only
    customInstructions: |
      Focus on clarity, proper formatting, and comprehensive examples. Always check for broken links and ensure consistency in tone and style.
    source: project
  - slug: test-engineer
    name: Test Engineer
    roleDefinition: |
      You are a QA engineer and testing specialist focused on writing comprehensive tests, debugging failures, and improving code coverage.
    groups:
      - read
      - command
      - - edit
        - fileRegex: \.(test|spec)\.(js|ts|jsx|tsx)$
          description: Test files only
    customInstructions: |
      Prioritize test readability, comprehensive edge cases, and clear assertion messages. Always consider both happy path and error scenarios.
    source: project

```

// FILE: .pre-commit-config.yaml
```
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

```

// FILE: AGENTS.md
```
# AGENTS.md

Інструкції для AI-агентів при роботі з Python проєктами.

## Менеджер пакетів

Завжди використовуй **uv** для всіх операцій з пакетами:

```bash
# Створення проєкту
uv init my-project

# Додавання залежностей
uv add requests pytest

# Додавання dev-залежностей
uv add --dev mypy ruff

# Встановлення залежностей
uv sync

# Запуск скриптів
uv run python main.py
uv run pytest
```

## Версіонування

Використовуй **semantic versioning** (MAJOR.MINOR.PATCH):

- **MAJOR** — несумісні зміни API (1.0.0 → 2.0.0)
- **MINOR** — нова функціональність, сумісна зі старою (1.0.0 → 1.1.0)
- **PATCH** — виправлення помилок (1.0.0 → 1.0.1)

```toml
# pyproject.toml
[project]
version = "1.2.3"
```

## Тестування

Використовуй **pytest**:

```bash
# Запуск тестів
uv run pytest

# З покриттям коду
uv run pytest --cov=src --cov-report=html

# Конкретний тест
uv run pytest tests/test_main.py::test_function
```

Структура тестів:

```python
# tests/test_main.py
import pytest
from src.main import add

def test_add():
    assert add(2, 3) == 5

def test_add_negative():
    assert add(-1, 1) == 0

@pytest.fixture
def sample_data():
    return {"key": "value"}

def test_with_fixture(sample_data):
    assert sample_data["key"] == "value"
```

## Перевірка типів

Використовуй **mypy**:

```bash
# Перевірка типів
uv run mypy src/

# З конфігурацією
uv run mypy --strict src/
```

Анотації типів:

```python
def greet(name: str, times: int = 1) -> str:
    return (name + "! ") * times

from typing import List, Dict, Optional

def process_items(items: List[str]) -> Dict[str, int]:
    return {item: len(item) for item in items}

def find_user(user_id: int) -> Optional[str]:
    return "Alice" if user_id == 1 else None
```



## Контрольний список

Перед комітом:
- [ ] `uv run pytest` — всі тести проходять
- [ ] `uv run mypy src/` — немає помилок типів

```

// FILE: CHANGELOG.md
```
# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Added `copy_async()` method for asynchronous file copying
- Added `append_text_async()` method for asynchronous text appending
- Added `read_bytes_async()` method for asynchronous byte reading
- Added `write_bytes_async()` method for asynchronous byte writing
- Added `indent` parameter to `dump_json()` and `dump_json_async()` methods for controlling JSON formatting
- Added `move()` and `move_async()` methods for moving/renaming files with automatic parent directory creation

### Changed
- Replaced aiofiles with asyncio.to_thread() in all async methods for better compatibility and reduced dependencies
- Replaced deprecated `asyncio.get_event_loop()` with `asyncio.to_thread()` in all async methods for Python 3.12+ compatibility
- `dump_json()` now properly formats JSON with indentation by default (2 spaces), matching the documented behavior
- `copy()` and `copy_async()` methods now return a `File` object for the target path, enabling fluent API usage
- Updated README.md examples to use generic application names instead of package version numbers

### Fixed
- Added missing `FileNotFoundError` documentation to `load_json()`, `load_yaml()`, `load_json_async()`, and `load_yaml_async()` method docstrings
- Fixed `write_bytes_async()` and `write_text_async()` methods to create parent directories automatically, matching the behavior of their synchronous counterparts

## [0.2.0] - 2025-12-23

### Added
- Typed deserialization support with dataclasses and TypedDict for JSON and YAML
- Custom exceptions: `FileOperationError`, `JSONDecodeError`, `YAMLDecodeError`
- Atomic writes for `dump_json()` and `dump_yaml()` methods
- Context manager `atomic_write()` for atomic file writes
- Async methods: `read_text_async()`, `write_text_async()`
- Async JSON methods: `load_json_async()`, `dump_json_async()`
- Async YAML methods: `load_yaml_async()`, `dump_yaml_async()`
- Utility method `append_text()` for appending text to files
- Utility method `touch_parents()` for creating file and parent directories
- Property `size` for getting file size in bytes

### Changed
- Replaced orjson with [msgspec](https://github.com/jcrist/msgspec) for JSON serialization/deserialization
- Replaced strictyaml with msgspec.yaml for YAML serialization/deserialization
- Improved performance (~1.5-2x faster for JSON/YAML operations)
- Reduced number of dependencies (single dependency: msgspec)

### Features
- Blazing fast JSON/YAML/MessagePack serialization powered by msgspec
- Type-safe deserialization with automatic validation
- Non-blocking async I/O operations
- Data integrity guaranteed by atomic writes
- Comprehensive error handling with custom exceptions

### Dependencies
- msgspec for JSON/YAML serialization/deserialization

## [0.1.0] - 2025-12-23

### Added
- Initial release of Easy File
- `File` class extending `pathlib.Path`
- UTF-8 default encoding for text file operations
- `open()` method with automatic UTF-8 encoding
- `copy()` method for file copying
- `load_json()` method for JSON deserialization
- `dump_json()` method for JSON serialization with formatting
- `load_yaml()` method for YAML deserialization
- `dump_yaml()` method for YAML serialization
- Automatic directory creation when writing files
- Full compatibility with all `pathlib.Path` methods

### Dependencies
- orjson for JSON serialization/deserialization
- strictyaml for YAML operations

```

// FILE: LICENSE
```
MIT License

Copyright (c) 2021, Ruslan Iskov

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


```

// FILE: mypy.ini
```
[mypy]
python_version = 3.12
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
disallow_incomplete_defs = True
check_untyped_defs = True
no_implicit_optional = True
warn_redundant_casts = True
warn_unused_ignores = True
warn_no_return = True
strict_equality = True


```

// FILE: pyproject.toml
```
[project]
name = "easy_file"
version = "0.4.0"
description = "Files for humans."
readme = "README.md"
requires-python = ">=3.12"
license = {text = "MIT"}
authors = [
    {name = "Ruslan Iskov", email = "ruslan.rv.ua@gmail.com"}
]
keywords = ["file", "pathlib", "json", "yaml"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Natural Language :: English",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: 3.14",
]

dependencies = [
    "msgspec>=0.18.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.0",
    "mypy>=1.5.0",
    "pre-commit>=3.5.0",
]

[project.urls]
Homepage = "https://github.com/ruslan-rv-ua/easy_file"
Repository = "https://github.com/ruslan-rv-ua/easy_file"
Issues = "https://github.com/ruslan-rv-ua/easy_file/issues"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/easy_file"]
artifacts = ["src/easy_file/py.typed"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"
addopts = [
    "--strict-markers",
    "--strict-config",
    "--cov=easy_file",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-report=xml",
]

[tool.ruff]
target-version = "py312"
line-length = 88

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "W",      # pycodestyle warnings
    "F",      # Pyflakes
    "I",      # isort
    "B",      # flake8-bugbear
    "C4",     # flake8-comprehensions
    "UP",     # pyupgrade
    "ARG",    # flake8-unused-arguments
    "SIM",    # flake8-simplify
]
ignore = [
    "E501",   # line too long (handled by formatter)
    "B008",   # do not perform function calls in argument defaults
    "C901",   # too complex
]

[tool.ruff.format]
indent-style = "space"
quote-style = "double"
skip-magic-trailing-comma = false

[dependency-groups]
dev = [
    "mypy>=1.19.1",
    "pre-commit>=4.5.1",
    "pytest>=9.0.2",
    "pytest-asyncio>=1.3.0",
    "pytest-cov>=7.0.0",
    "ruff>=0.14.10",
]

```

// FILE: README.md
```
# Easy File

<p align="center">
<a href="https://pypi.python.org/pypi/easy_file">
    <img src="https://img.shields.io/pypi/v/easy_file.svg" alt="Release Status">
</a>
<a href="LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License">
</a>
</p>

**Files for humans.**

Easy File extends Python's `pathlib.Path` to provide a more convenient, robust, and feature-rich interface for file operations.

## Features

* **Pathlib based**: Inherits all standard `pathlib.Path` operations.
* **UTF-8 by default**: No more encoding headaches; text operations default to UTF-8.
* **Fast Serialization**: Blazing fast JSON and YAML serialization using [msgspec](https://github.com/jcrist/msgspec).
* **Typed Deserialization**: Support for `TypedDict` and `dataclasses` for type-safe data loading.
* **Atomic Writes**: guarantees data integrity by writing to a temporary file first.
* **Async Support**: Full suite of async methods for non-blocking I/O.
* **Automatic Directories**: Automatically creates parent directories when writing files.
* **Robust Error Handling**: Custom exceptions for clear failure modes.

## Installation

```bash
pip install easy_file
```

## Quick Start

```python
from easy_file import File

# File operations with UTF-8 by default
f = File("data.txt")
f.write_text("Hello World!")
content = f.read_text()  # "Hello World!"

# JSON operations
config = File("config.json")
config.dump_json({"name": "My App", "version": "1.0.0"})
data = config.load_json()  # {"name": "My App", "version": "1.0.0"}

# YAML operations
settings = File("settings.yaml")
settings.dump_yaml({"debug": True, "port": 8080})
yaml_data = settings.load_yaml()  # {"debug": True, "port": 8080}

# Copy and Move
source = File("source.txt").write_text("content")
backup = source.copy("backup.txt")
moved = source.move("renamed.txt")

# All pathlib.Path methods are available
f = File("path/to/file.txt")
print(f.name)      # "file.txt"
print(f.parent)    # "path/to"
print(f.suffix)    # ".txt"
```

## Advanced Usage

### Typed Deserialization

Easy File supports typed deserialization for JSON and YAML using `TypedDict` and `dataclasses`. This provides IDE autocompletion and runtime validation.

#### Using TypedDict

```python
from typing import TypedDict
from easy_file import File

class Config(TypedDict):
    name: str
    version: str
    debug: bool

config = File("config.json")
config.dump_json({"name": "My App", "version": "1.0.0", "debug": True})

# Typed deserialization
data: Config = config.load_json(Config)
print(data["name"])  # "My App"
```

#### Using Dataclasses

```python
from dataclasses import dataclass
from easy_file import File

@dataclass
class Settings:
    debug: bool
    port: int
    host: str

settings = File("settings.yaml")
settings.dump_yaml({"debug": True, "port": 8080, "host": "localhost"})

# Typed deserialization
data: Settings = settings.load_yaml(Settings)
print(data.port)  # 8080
```

### Async Methods

Easy File provides asynchronous versions of all major I/O operations for non-blocking execution.

```python
import asyncio
from easy_file import File

async def main():
    f = File("data.txt")
    
    # Text operations
    await f.write_text_async("Hello async!")
    content = await f.read_text_async()
    await f.append_text_async("\nMore content")
    
    # Binary operations
    await f.write_bytes_async(b"Binary data")
    data = await f.read_bytes_async()

    # JSON/YAML operations
    config = File("config.json")
    await config.dump_json_async({"async": True}, indent=2)
    data = await config.load_json_async()
    
    # File management
    await f.copy_async("backup.txt")
    await f.move_async("archive/data.txt")

asyncio.run(main())
```

#### Batch File Reading

Read multiple files in parallel using the `read_many_async()` class method:

```python
import asyncio
from easy_file import File

async def main():
    # Create test files
    File("file1.txt").write_text("Content 1")
    File("file2.txt").write_text("Content 2")
    File("file3.txt").write_text("Content 3")
    
    # Read all files in parallel
    paths = ["file1.txt", "file2.txt", "file3.txt"]
    contents = await File.read_many_async(paths)
    
    print(contents)  # ['Content 1', 'Content 2', 'Content 3']

asyncio.run(main())
```

This is especially useful when you need to read many files at once, as it leverages asyncio to perform all reads concurrently.

### Atomic Writes

Data integrity is crucial. Easy File uses atomic writes for `dump_json` and `dump_yaml` by default. You can also use the `atomic_write` context manager for arbitrary data.

```python
from easy_file import File

f = File("important.txt")

# Using the context manager
with f.atomic_write() as file:
    file.write("This write is atomic.")
    # If an error occurs here, the original file remains untouched.
```

### Utility Methods

Helper methods for common tasks.

* **`append_text(text)`**: Safely append text to a file.
* **`touch_parents()`**: Create a file and all necessary parent directories.
* **`size`**: Property to get file size in bytes.

```python
log = File("logs/app.log")
log.touch_parents()
log.append_text("Started.\n")
print(log.size)
```

### Error Handling

Custom exceptions help catch specific errors.

* `FileOperationError`: Base class for all Easy File errors.
* `JSONDecodeError`: Failed to decode JSON.
* `YAMLDecodeError`: Failed to decode YAML.

```python
from easy_file import File, JSONDecodeError, FileOperationError

try:
    data = File("config.json").load_json()
except JSONDecodeError:
    print("Invalid JSON format")
except FileOperationError as e:
    print(f"File error: {e}")
```

## API Reference

### Core Methods
* `File(path)`: Initialize a new File object.
* `open(mode, ...)`: Open file (defaults to UTF-8).
* `copy(target)`: Copy file to target.
* `move(target)`: Move/rename file to target.
* `touch_parents()`: Create file and parents.

### Data Methods
* `load_json(type=None)` / `dump_json(data, indent=2)`
* `load_yaml(type=None)` / `dump_yaml(data)`
* `read_text(encoding='utf-8')` / `write_text(data, ...)`
* `read_bytes()` / `write_bytes(data)`
* `append_text(text)`

### Async Methods
* `copy_async(target)` / `move_async(target)`
* `load_json_async(type=None)` / `dump_json_async(data, indent=2)`
* `load_yaml_async(type=None)` / `dump_yaml_async(data)`
* `read_text_async()` / `write_text_async(data)`
* `read_bytes_async()` / `write_bytes_async(data)`
* `append_text_async(text)`
* `read_many_async(paths)` - Class method to read multiple files in parallel

### Properties
* `size`: File size in bytes.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```

// FILE: src/easy_file/__init__.py
```
"""Easy File - Files for humans."""

from importlib.metadata import PackageNotFoundError, version

try:
    __version__ = version("easy_file")
except PackageNotFoundError:
    __version__ = "0.0.0.dev0"

from easy_file.easy_file import (
    File,
    FileOperationError,
    JSONDecodeError,
    YAMLDecodeError,
)

__all__ = [
    "__version__",
    "File",
    "FileOperationError",
    "JSONDecodeError",
    "YAMLDecodeError",
]

```

// FILE: src/easy_file/easy_file.py
```
"""Easy File - Files for humans."""

from __future__ import annotations

import asyncio
import os
import pathlib
from contextlib import contextmanager, suppress
from typing import Any, BinaryIO, TextIO, TypeVar, cast, overload

import msgspec

# Global encoder and decoder for msgspec JSON
_json_encoder = msgspec.json.Encoder()
_json_decoder = msgspec.json.Decoder()
# msgspec.yaml uses encode/decode functions, not Encoder/Decoder classes

# Type variable for generic return types
_T = TypeVar("_T")


class FileOperationError(Exception):
    """Base exception for file operation errors."""

    pass


class JSONDecodeError(FileOperationError):
    """Exception raised when JSON decoding fails."""

    pass


class YAMLDecodeError(FileOperationError):
    """Exception raised when YAML decoding fails."""

    pass


class File(pathlib.Path):
    """Extended Path class with convenient file operations.

    Provides methods for JSON and YAML operations, copying, and
    UTF-8 default encoding for text files.

    Example:
        >>> from easy_file import File
        >>> f = File("data.txt")
        >>> f.write_text("Hello, world!")
        >>> f.read_text()
        'Hello, world!'
    """

    __slots__ = ()  # Path вже має __slots__

    def open(  # type: ignore[override]
        self,
        mode: str = "r",
        buffering: int = -1,
        encoding: str | None = None,
        errors: str | None = None,
        newline: str | None = None,
        **kwargs: Any,
    ) -> TextIO | BinaryIO:
        """Open the file with UTF-8 default encoding for text modes.
        Forwards additional arguments to pathlib.Path.open().

        Args:
            mode: File opening mode ('r', 'w', 'rb', 'wb', etc.)
            buffering: Buffering policy (-1 for default)
            encoding: Text encoding (defaults to UTF-8 for text modes)
            errors: Error handling strategy
            newline: Newline handling
            **kwargs: Additional arguments forwarded to pathlib.Path.open()

        Returns:
            File object (TextIO or BinaryIO)

        Example:
            >>> f = File("example.txt")
            >>> with f.open("w") as file:
            ...     file.write("Привіт світ!")
            >>> with f.open() as file:
            ...     content = file.read()
            >>> print(content)
            Привіт світ!
        """
        if encoding is None and "b" not in mode:
            encoding = "utf-8"
        return cast(
            TextIO | BinaryIO,
            super().open(mode, buffering, encoding, errors, newline, **kwargs),
        )

    def copy(
        self, target_path: str | pathlib.Path, preserve_metadata: bool = True
    ) -> File:
        """Copy this file to the target path.

        Args:
            target_path: Destination path for the copy
            preserve_metadata: Whether to preserve file metadata (timestamps, permissions).
                               Defaults to True (uses shutil.copy2).
                               If False, uses shutil.copy.

        Returns:
            File object for the target path

        Example:
            >>> source = File("source.txt")
            >>> source.write_text("Original content")
            >>> backup = source.copy("backup.txt")
            >>> backup.read_text()
            'Original content'
        """
        import shutil  # Lazy import

        target = File(target_path)
        target.parent.mkdir(parents=True, exist_ok=True)

        if preserve_metadata:
            shutil.copy2(self, target)
        else:
            shutil.copy(self, target)

        return target

    def move(self, target_path: str | pathlib.Path) -> File:
        """Move this file to the target path.

        Args:
            target_path: Destination path for the move

        Returns:
            File object for the target path

        Example:
            >>> source = File("source.txt")
            >>> source.write_text("Content")
            >>> moved = source.move("target.txt")
            >>> moved.read_text()
            'Content'
            >>> source.exists()
            False
        """
        import shutil  # Lazy import

        target = File(target_path)
        target.parent.mkdir(parents=True, exist_ok=True)
        shutil.move(str(self), str(target))
        return target

    @overload
    def load_json(self) -> Any: ...

    @overload
    def load_json(self, type: type[_T]) -> _T: ...

    def load_json(self, type: type[_T] | None = None) -> Any:
        """Load JSON data from this file.

        Args:
            type: Optional type for typed deserialization.
                  If provided, returns data of the specified type.

        Returns:
            Parsed JSON data (dict, list, or other JSON-compatible type)
            If type is provided, returns data of the specified type.

        Raises:
            JSONDecodeError: If JSON decoding fails
            FileNotFoundError: If the file doesn't exist

        Example:
            >>> config = File("config.json")
            >>> config.dump_json({"name": "Easy File", "version": "0.4.0"})
            >>> data = config.load_json()
            >>> print(data)
            {'name': 'Easy File', 'version': '0.4.0'}

        Example with type:
            >>> from typing import TypedDict
            >>> class Config(TypedDict):
            ...     name: str
            ...     version: str
            >>> config = File("config.json")
            >>> config.dump_json({"name": "Easy File", "version": "0.4.0"})
            >>> data = config.load_json(Config)
            >>> print(data["name"])
            Easy File
        """
        try:
            content = self.read_bytes()
            if type is not None:
                return msgspec.json.decode(content, type=type)
            return _json_decoder.decode(content)
        except msgspec.DecodeError as e:
            raise JSONDecodeError(f"Failed to decode JSON from {self}: {e}") from e

    def _atomic_write_bytes(self, data: bytes) -> None:
        """Internal method for atomic write of bytes data.

        Creates a temporary file, writes the data, flushes to disk,
        and atomically renames it to the target path. Ensures data
        integrity even if the process crashes during write.

        Args:
            data: Bytes to write atomically

        Raises:
            OSError: If write or rename fails
        """
        import tempfile  # Lazy import

        self.parent.mkdir(parents=True, exist_ok=True)

        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(
                mode="wb",
                dir=self.parent,
                prefix=f".{self.name}.",
                delete=False,
            ) as tmp_file:
                tmp_path = tmp_file.name
                tmp_file.write(data)
                tmp_file.flush()
                os.fsync(tmp_file.fileno())
                # Явне закриття перед rename на Windows
                tmp_file.close()

            os.replace(tmp_path, self)
        except Exception:
            if tmp_path is not None and os.path.exists(tmp_path):
                with suppress(OSError):
                    os.remove(tmp_path)
            raise

    def dump_json(self, data: Any, indent: int = 2) -> None:
        """Dump data to this file as formatted JSON.

        Uses atomic writes to ensure data integrity.

        Args:
            data: Data to serialize as JSON
            indent: Number of spaces for indentation (default: 2).
                    Set to 0 for compact output.

        Example:
            >>> config = File("config.json")
            >>> config.dump_json({"name": "Easy File", "version": "0.4.0"})
            >>> config.read_text()
            '{\\n  "name": "Easy File",\\n  "version": "0.4.0"\\n}'
        """
        if indent > 0:
            json_bytes = msgspec.json.format(
                _json_encoder.encode(data),
                indent=indent,
            )
        else:
            json_bytes = _json_encoder.encode(data)

        self._atomic_write_bytes(json_bytes)

    @overload
    def load_yaml(self) -> Any: ...

    @overload
    def load_yaml(self, type: type[_T]) -> _T: ...

    def load_yaml(self, type: type[_T] | None = None) -> Any:
        """Load YAML data from this file.

        Args:
            type: Optional type for typed deserialization.
                  If provided, returns data of the specified type.

        Returns:
            Parsed YAML data (dict, list, or other YAML-compatible type)
            If type is provided, returns data of the specified type.

        Raises:
            YAMLDecodeError: If YAML decoding fails
            FileNotFoundError: If the file doesn't exist

        Example:
            >>> settings = File("settings.yaml")
            >>> settings.dump_yaml({"debug": True, "port": 8080})
            >>> data = settings.load_yaml()
            >>> print(data)
            {'debug': True, 'port': 8080}

        Example with type:
            >>> from typing import TypedDict
            >>> class Settings(TypedDict):
            ...     debug: bool
            ...     port: int
            >>> settings = File("settings.yaml")
            >>> settings.dump_yaml({"debug": True, "port": 8080})
            >>> data = settings.load_yaml(Settings)
            >>> print(data["debug"])
            True
        """
        try:
            content = self.read_bytes()
            if type is not None:
                return msgspec.yaml.decode(content, type=type)
            return msgspec.yaml.decode(content)
        except msgspec.DecodeError as e:
            raise YAMLDecodeError(f"Failed to decode YAML from {self}: {e}") from e

    def dump_yaml(self, data: Any) -> None:
        """Dump data to this file as YAML.

        Uses atomic writes to ensure data integrity.

        Args:
            data: Data to serialize as YAML

        Example:
            >>> settings = File("settings.yaml")
            >>> settings.dump_yaml({"debug": True, "port": 8080})
            >>> settings.read_text()
            'debug: true\\nport: 8080\\n'
        """
        yaml_bytes = msgspec.yaml.encode(data)
        self._atomic_write_bytes(yaml_bytes)

    @contextmanager
    def atomic_write(self, mode: str = "w", encoding: str | None = None) -> Any:
        """Context manager for atomic file writes.

        Writes to a temporary file and atomically renames it to the target
        path when the context exits successfully.

        Args:
            mode: File opening mode (default: 'w')
            encoding: Text encoding (defaults to UTF-8 for text modes)

        Yields:
            File object for writing

        Raises:
            ValueError: If encoding is specified in binary mode

        Example:
            >>> f = File("data.txt")
            >>> with f.atomic_write() as file:
            ...     file.write("Atomic content")
            >>> f.read_text()
            'Atomic content'
        """
        import tempfile  # Lazy import

        if encoding is not None and "b" in mode:
            raise ValueError("encoding argument not supported in binary mode")

        if encoding is None and "b" not in mode:
            encoding = "utf-8"

        self.parent.mkdir(parents=True, exist_ok=True)

        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile(
                mode=mode,
                dir=self.parent,
                prefix=f".{self.name}.",
                encoding=encoding,
                delete=False,
            ) as tmp_file:
                tmp_path = pathlib.Path(tmp_file.name)
                try:
                    yield tmp_file
                    tmp_file.flush()
                    # Close the file before replace/unlink to avoid Windows file lock issues
                    tmp_file.close()
                except Exception:
                    # Close the file before unlink to avoid Windows file lock issues
                    tmp_file.close()
                    raise
                else:
                    tmp_path.replace(self)
        except Exception:
            if tmp_path is not None and tmp_path.exists():
                with suppress(OSError):
                    tmp_path.unlink(missing_ok=True)
            raise

    async def read_text_async(
        self, encoding: str = "utf-8", errors: str | None = None
    ) -> str:
        """Asynchronously read text from this file.

        Args:
            encoding: Text encoding (default: 'utf-8')
            errors: Error handling strategy

        Returns:
            File content as string

        Example:
            >>> import asyncio
            >>> f = File("data.txt")
            >>> f.write_text("Hello")
            >>> content = asyncio.run(f.read_text_async())
            >>> print(content)
            Hello
        """
        return await asyncio.to_thread(self.read_text, encoding, errors)

    async def write_text_async(
        self,
        data: str,
        encoding: str = "utf-8",
        errors: str | None = None,
    ) -> None:
        """Asynchronously write text to this file.

        Args:
            data: Text to write
            encoding: Text encoding (default: 'utf-8')
            errors: Error handling strategy

        Example:
            >>> import asyncio
            >>> f = File("data.txt")
            >>> asyncio.run(f.write_text_async("Hello async"))
            >>> f.read_text()
            'Hello async'
        """
        await asyncio.to_thread(self.write_text, data, encoding, errors)

    @overload
    async def load_json_async(self) -> Any: ...

    @overload
    async def load_json_async(self, type: type[_T]) -> _T: ...

    async def load_json_async(self, type: type[_T] | None = None) -> Any:
        """Asynchronously load JSON data from this file.

        Args:
            type: Optional type for typed deserialization.

        Returns:
            Parsed JSON data

        Raises:
            JSONDecodeError: If JSON decoding fails
            FileNotFoundError: If the file doesn't exist

        Example:
            >>> import asyncio
            >>> config = File("config.json")
            >>> config.dump_json({"name": "Easy File"})
            >>> data = asyncio.run(config.load_json_async())
            >>> print(data)
            {'name': 'Easy File'}
        """

        def _load() -> Any:
            return self.load_json(type)  # type: ignore[arg-type]

        return await asyncio.to_thread(_load)

    async def dump_json_async(self, data: Any, indent: int = 2) -> None:
        """Asynchronously dump data to this file as formatted JSON.

        Args:
            data: Data to serialize as JSON
            indent: Number of spaces for indentation (default: 2).
                    Set to 0 for compact output.

        Example:
            >>> import asyncio
            >>> config = File("config.json")
            >>> asyncio.run(config.dump_json_async({"name": "Easy File"}))
            >>> config.read_text()
            '{\\n  "name": "Easy File"\\n}'
        """
        await asyncio.to_thread(self.dump_json, data, indent)

    @overload
    async def load_yaml_async(self) -> Any: ...

    @overload
    async def load_yaml_async(self, type: type[_T]) -> _T: ...

    async def load_yaml_async(self, type: type[_T] | None = None) -> Any:
        """Asynchronously load YAML data from this file.

        Args:
            type: Optional type for typed deserialization.

        Returns:
            Parsed YAML data

        Raises:
            YAMLDecodeError: If YAML decoding fails
            FileNotFoundError: If the file doesn't exist

        Example:
            >>> import asyncio
            >>> settings = File("settings.yaml")
            >>> settings.dump_yaml({"debug": True})
            >>> data = asyncio.run(settings.load_yaml_async())
            >>> print(data)
            {'debug': True}
        """

        def _load() -> Any:
            return self.load_yaml(type)  # type: ignore[arg-type]

        return await asyncio.to_thread(_load)

    async def dump_yaml_async(self, data: Any) -> None:
        """Asynchronously dump data to this file as YAML.

        Args:
            data: Data to serialize as YAML

        Example:
            >>> import asyncio
            >>> settings = File("settings.yaml")
            >>> asyncio.run(settings.dump_yaml_async({"debug": True}))
            >>> settings.read_text()
            'debug: true\\n'
        """
        await asyncio.to_thread(self.dump_yaml, data)

    async def copy_async(
        self, target_path: str | pathlib.Path, preserve_metadata: bool = True
    ) -> File:
        """Asynchronously copy this file to the target path.

        Args:
            target_path: Destination path for the copy
            preserve_metadata: Whether to preserve file metadata (timestamps, permissions).
                               Defaults to True (uses shutil.copy2).
                               If False, uses shutil.copy.

        Returns:
            File object for the target path

        Example:
            >>> import asyncio
            >>> source = File("source.txt")
            >>> source.write_text("Original content")
            >>> backup = asyncio.run(source.copy_async("backup.txt"))
            >>> backup.read_text()
            'Original content'
        """
        return await asyncio.to_thread(self.copy, target_path, preserve_metadata)

    async def move_async(self, target_path: str | pathlib.Path) -> File:
        """Asynchronously move this file to the target path.

        Args:
            target_path: Destination path for the move

        Returns:
            File object for the target path

        Example:
            >>> import asyncio
            >>> source = File("source.txt")
            >>> source.write_text("Content")
            >>> moved = asyncio.run(source.move_async("target.txt"))
            >>> moved.read_text()
            'Content'
        """
        return await asyncio.to_thread(self.move, target_path)

    async def append_text_async(
        self,
        text: str,
        encoding: str = "utf-8",
        errors: str | None = None,
    ) -> None:
        """Asynchronously append text to this file.

        Args:
            text: Text to append
            encoding: Text encoding (default: 'utf-8')
            errors: Error handling strategy

        Example:
            >>> import asyncio
            >>> f = File("log.txt")
            >>> f.write_text("First line\\n")
            >>> asyncio.run(f.append_text_async("Second line\\n"))
            >>> f.read_text()
            'First line\\nSecond line\\n'
        """
        await asyncio.to_thread(self.append_text, text, encoding, errors)

    async def read_bytes_async(self) -> bytes:
        """Asynchronously read bytes from this file.

        Returns:
            File content as bytes

        Example:
            >>> import asyncio
            >>> f = File("data.bin")
            >>> f.write_bytes(b"\\x00\\x01\\x02")
            >>> content = asyncio.run(f.read_bytes_async())
            >>> print(content)
            b'\\x00\\x01\\x02'
        """
        return await asyncio.to_thread(self.read_bytes)

    async def write_bytes_async(self, data: bytes) -> None:
        """Asynchronously write bytes to this file.

        Args:
            data: Bytes to write

        Example:
            >>> import asyncio
            >>> f = File("data.bin")
            >>> asyncio.run(f.write_bytes_async(b"\\x00\\x01\\x02"))
            >>> f.read_bytes()
            b'\\x00\\x01\\x02'
        """
        await asyncio.to_thread(self.write_bytes, data)

    @classmethod
    async def read_many_async(cls, paths: list[str | pathlib.Path]) -> list[str]:
        """Читати багато файлів паралельно.

        Args:
            paths: Список шляхів до файлів для читання

        Returns:
            Список вмісту файлів у тому ж порядку, що й шляхи

        Example:
            >>> import asyncio
            >>> File("file1.txt").write_text("Content 1")
            >>> File("file2.txt").write_text("Content 2")
            >>> contents = asyncio.run(File.read_many_async(["file1.txt", "file2.txt"]))
            >>> print(contents)
            ['Content 1', 'Content 2']
        """
        tasks = [cls(p).read_text_async() for p in paths]
        return await asyncio.gather(*tasks)

    def append_text(
        self,
        text: str,
        encoding: str = "utf-8",
        errors: str | None = None,
    ) -> None:
        """Append text to this file.

        Args:
            text: Text to append
            encoding: Text encoding (default: 'utf-8')
            errors: Error handling strategy

        Example:
            >>> f = File("log.txt")
            >>> f.write_text("First line\\n")
            >>> f.append_text("Second line\\n")
            >>> f.read_text()
            'First line\\nSecond line\\n'
        """
        self.parent.mkdir(parents=True, exist_ok=True)
        with self.open(mode="a", encoding=encoding, errors=errors) as f:
            cast(TextIO, f).write(text)

    def touch_parents(self) -> None:
        """Create this file and all parent directories if they don't exist.

        Similar to `touch` command but also creates parent directories.

        Example:
            >>> f = File("nested/deep/file.txt")
            >>> f.touch_parents()
            >>> f.exists()
            True
        """
        self.parent.mkdir(parents=True, exist_ok=True)
        self.touch()

    @property
    def size(self) -> int:
        """Get the size of this file in bytes.

        Returns:
            File size in bytes

        Raises:
            FileNotFoundError: If the file doesn't exist

        Example:
            >>> f = File("data.txt")
            >>> f.write_text("Hello")
            >>> f.size
            5
        """
        return self.stat().st_size

```

// FILE: src/easy_file/py.typed
```

```

// FILE: tests/__init__.py
```
"""Unit test package for easy_file."""

```

// FILE: tests/conftest.py
```
"""Pytest configuration and shared fixtures."""

import pathlib
import tempfile
from collections.abc import Generator

import pytest


@pytest.fixture
def temp_dir() -> Generator[pathlib.Path, None, None]:
    """Create a temporary directory for testing.

    Yields:
        Path to temporary directory
    """
    with tempfile.TemporaryDirectory() as tmpdir:
        yield pathlib.Path(tmpdir)


@pytest.fixture
def sample_json_data() -> dict[str, object]:
    """Sample JSON data for testing.

    Returns:
        Dictionary with sample data
    """
    return {
        "name": "test",
        "value": 42,
        "nested": {"key": "value"},
        "list": [1, 2, 3],
    }


@pytest.fixture
def sample_yaml_data() -> dict[str, object]:
    """Sample YAML data for testing.

    Returns:
        Dictionary with sample data
    """
    return {
        "name": "test",
        "value": 42,
        "nested": {"key": "value"},
        "list": [1, 2, 3],
    }

```

// FILE: tests/test_easy_file.py
```
"""Tests for easy_file package."""

import pathlib
from dataclasses import dataclass
from typing import TypedDict

import pytest

from easy_file import File
from easy_file.easy_file import FileOperationError, JSONDecodeError, YAMLDecodeError


# Test dataclasses and TypedDict for typed deserialization tests
@dataclass
class Person:
    """Test dataclass for typed deserialization."""

    name: str
    age: int
    email: str


class Config(TypedDict):
    """Test TypedDict for typed deserialization."""

    name: str
    version: str
    debug: bool


class Settings(TypedDict):
    """Test TypedDict for YAML typed deserialization."""

    port: int
    host: str
    enabled: bool


class TestFileOpen:
    """Test File.open() method."""

    def test_open_text_default_encoding(self, temp_dir: pathlib.Path) -> None:
        """Test that text files open with UTF-8 encoding by default."""
        test_file = File(temp_dir / "test.txt")
        test_file.write_text("Привіт світ!", encoding="utf-8")

        with test_file.open() as f:
            content = f.read()

        assert content == "Привіт світ!"

    def test_open_binary_mode(self, temp_dir: pathlib.Path) -> None:
        """Test binary mode opening."""
        test_file = File(temp_dir / "test.bin")
        test_file.write_bytes(b"\x00\x01\x02")

        with test_file.open("rb") as f:
            content = f.read()

        assert content == b"\x00\x01\x02"


class TestFileCopy:
    """Test File.copy() method."""

    def test_copy_file(self, temp_dir: pathlib.Path) -> None:
        """Test copying a file."""
        source = File(temp_dir / "source.txt")
        target = File(temp_dir / "target.txt")

        source.write_text("test content")
        source.copy(target)

        assert target.exists()
        assert target.read_text() == "test content"

    def test_copy_binary_file(self, temp_dir: pathlib.Path) -> None:
        """Test copying a binary file."""
        source = File(temp_dir / "source.bin")
        target = File(temp_dir / "target.bin")

        source.write_bytes(b"\x00\x01\x02\x03")
        source.copy(target)

        assert target.exists()
        assert target.read_bytes() == b"\x00\x01\x02\x03"

    def test_copy_creates_parent_directories(self, temp_dir: pathlib.Path) -> None:
        """Test that copy creates parent directories if needed."""
        source = File(temp_dir / "source.txt")
        target = File(temp_dir / "nested" / "deep" / "target.txt")

        source.write_text("test content")
        source.copy(target)

        assert target.exists()
        assert target.read_text() == "test content"

    def test_copy_without_metadata(self, temp_dir: pathlib.Path) -> None:
        """Test copying a file without preserving metadata."""
        source = File(temp_dir / "source.txt")
        target = File(temp_dir / "target.txt")

        source.write_text("test content")
        source.copy(target, preserve_metadata=False)

        assert target.exists()
        assert target.read_text() == "test content"


class TestFileMove:
    """Test File.move() method."""

    def test_move_file(self, temp_dir: pathlib.Path) -> None:
        """Test moving a file."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("test content")
        moved = source.move(target_path)

        assert moved.exists()
        assert moved.read_text() == "test content"
        assert not source.exists()

    def test_move_creates_parent_directories(self, temp_dir: pathlib.Path) -> None:
        """Test that move creates parent directories if needed."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "nested" / "deep" / "target.txt"

        source.write_text("test content")
        moved = source.move(target_path)

        assert moved.exists()
        assert moved.read_text() == "test content"
        assert not source.exists()

    def test_move_source_deleted(self, temp_dir: pathlib.Path) -> None:
        """Test that source file is deleted after move."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("content to move")
        source.move(target_path)

        assert not source.exists()
        assert File(target_path).exists()

    def test_move_overwrites_existing(self, temp_dir: pathlib.Path) -> None:
        """Test that move overwrites existing target file."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("new content")
        target = File(target_path)
        target.write_text("old content")

        moved = source.move(target_path)

        assert moved.exists()
        assert moved.read_text() == "new content"
        assert not source.exists()

    def test_move_missing_source(self, temp_dir: pathlib.Path) -> None:
        """Test that moving a missing source raises FileNotFoundError."""
        source = File(temp_dir / "missing.txt")
        target_path = temp_dir / "target.txt"

        with pytest.raises(FileNotFoundError):
            source.move(target_path)


class TestFileJson:
    """Test File JSON operations."""

    def test_load_json(
        self, temp_dir: pathlib.Path, sample_json_data: dict[str, object]
    ) -> None:
        """Test loading JSON from file."""
        import msgspec

        test_file = File(temp_dir / "test.json")
        test_file.write_bytes(msgspec.json.encode(sample_json_data))

        loaded = test_file.load_json()

        assert loaded == sample_json_data

    def test_dump_json(
        self, temp_dir: pathlib.Path, sample_json_data: dict[str, object]
    ) -> None:
        """Test dumping JSON to file."""
        test_file = File(temp_dir / "test.json")
        test_file.dump_json(sample_json_data)

        loaded = test_file.load_json()

        assert loaded == sample_json_data

    def test_json_roundtrip(
        self, temp_dir: pathlib.Path, sample_json_data: dict[str, object]
    ) -> None:
        """Test JSON dump and load roundtrip."""
        test_file = File(temp_dir / "test.json")
        test_file.dump_json(sample_json_data)
        loaded = test_file.load_json()

        assert loaded == sample_json_data

    def test_load_json_with_typeddict(self, temp_dir: pathlib.Path) -> None:
        """Test loading JSON with TypedDict type."""
        test_file = File(temp_dir / "config.json")
        test_file.dump_json({"name": "Easy File", "version": "0.4.0", "debug": True})

        loaded = test_file.load_json(Config)

        assert loaded["name"] == "Easy File"
        assert loaded["version"] == "0.4.0"
        assert loaded["debug"] is True

    def test_load_json_with_dataclass(self, temp_dir: pathlib.Path) -> None:
        """Test loading JSON with dataclass type."""
        test_file = File(temp_dir / "person.json")
        test_file.dump_json({"name": "John", "age": 30, "email": "john@example.com"})

        loaded = test_file.load_json(Person)

        assert loaded.name == "John"
        assert loaded.age == 30
        assert loaded.email == "john@example.com"

    def test_load_json_invalid_json(self, temp_dir: pathlib.Path) -> None:
        """Test loading invalid JSON raises JSONDecodeError."""
        test_file = File(temp_dir / "invalid.json")
        test_file.write_text("{invalid json}")

        with pytest.raises(JSONDecodeError) as exc_info:
            test_file.load_json()

        assert "Failed to decode JSON" in str(exc_info.value)

    def test_load_json_missing_file(self, temp_dir: pathlib.Path) -> None:
        """Test loading JSON from missing file raises FileNotFoundError."""
        test_file = File(temp_dir / "missing.json")

        with pytest.raises(FileNotFoundError):
            test_file.load_json()

    def test_dump_json_creates_parent_directories(self, temp_dir: pathlib.Path) -> None:
        """Test that dump_json creates parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "data.json")
        test_file.dump_json({"test": "data"})

        assert test_file.exists()
        assert test_file.load_json() == {"test": "data"}

    def test_dump_json_atomic_write(self, temp_dir: pathlib.Path) -> None:
        """Test that dump_json uses atomic writes."""
        test_file = File(temp_dir / "atomic.json")
        test_file.dump_json({"initial": "data"})

        # Simulate concurrent write by checking file exists during write
        # The atomic write should ensure data integrity
        test_file.dump_json({"updated": "data"})

        loaded = test_file.load_json()
        assert loaded == {"updated": "data"}
        # File should always contain valid JSON
        assert test_file.exists()


class TestFileYaml:
    """Test File YAML operations."""

    def test_load_yaml(
        self, temp_dir: pathlib.Path, sample_yaml_data: dict[str, object]
    ) -> None:
        """Test loading YAML from file."""
        test_file = File(temp_dir / "test.yaml")
        test_file.write_text(
            "name: test\nvalue: 42\nnested:\n  key: value\nlist:\n  - 1\n  - 2\n  - 3\n"
        )

        loaded = test_file.load_yaml()

        assert loaded == sample_yaml_data

    def test_dump_yaml(
        self, temp_dir: pathlib.Path, sample_yaml_data: dict[str, object]
    ) -> None:
        """Test dumping YAML to file."""
        test_file = File(temp_dir / "test.yaml")
        test_file.dump_yaml(sample_yaml_data)

        loaded = test_file.load_yaml()

        assert loaded == sample_yaml_data

    def test_yaml_roundtrip(
        self, temp_dir: pathlib.Path, sample_yaml_data: dict[str, object]
    ) -> None:
        """Test YAML dump and load roundtrip."""
        test_file = File(temp_dir / "test.yaml")
        test_file.dump_yaml(sample_yaml_data)
        loaded = test_file.load_yaml()

        assert loaded == sample_yaml_data

    def test_load_yaml_with_typeddict(self, temp_dir: pathlib.Path) -> None:
        """Test loading YAML with TypedDict type."""
        test_file = File(temp_dir / "settings.yaml")
        test_file.dump_yaml({"port": 8080, "host": "localhost", "enabled": True})

        loaded = test_file.load_yaml(Settings)

        assert loaded["port"] == 8080
        assert loaded["host"] == "localhost"
        assert loaded["enabled"] is True

    def test_load_yaml_with_dataclass(self, temp_dir: pathlib.Path) -> None:
        """Test loading YAML with dataclass type."""
        test_file = File(temp_dir / "person.yaml")
        test_file.dump_yaml({"name": "Jane", "age": 25, "email": "jane@example.com"})

        loaded = test_file.load_yaml(Person)

        assert loaded.name == "Jane"
        assert loaded.age == 25
        assert loaded.email == "jane@example.com"

    def test_load_yaml_invalid_yaml(self, temp_dir: pathlib.Path) -> None:
        """Test loading invalid YAML raises YAMLDecodeError."""
        test_file = File(temp_dir / "invalid.yaml")
        test_file.write_text("invalid: yaml: content:\n  - broken")

        with pytest.raises(YAMLDecodeError) as exc_info:
            test_file.load_yaml()

        assert "Failed to decode YAML" in str(exc_info.value)

    def test_load_yaml_missing_file(self, temp_dir: pathlib.Path) -> None:
        """Test loading YAML from missing file raises FileNotFoundError."""
        test_file = File(temp_dir / "missing.yaml")

        with pytest.raises(FileNotFoundError):
            test_file.load_yaml()

    def test_dump_yaml_creates_parent_directories(self, temp_dir: pathlib.Path) -> None:
        """Test that dump_yaml creates parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "data.yaml")
        test_file.dump_yaml({"test": "data"})

        assert test_file.exists()
        assert test_file.load_yaml() == {"test": "data"}

    def test_dump_yaml_atomic_write(self, temp_dir: pathlib.Path) -> None:
        """Test that dump_yaml uses atomic writes."""
        test_file = File(temp_dir / "atomic.yaml")
        test_file.dump_yaml({"initial": "data"})

        test_file.dump_yaml({"updated": "data"})

        loaded = test_file.load_yaml()
        assert loaded == {"updated": "data"}
        assert test_file.exists()


class TestFileErrors:
    """Test error handling in File operations."""

    def test_file_operation_error_is_exception(self) -> None:
        """Test that FileOperationError is an Exception."""
        assert issubclass(FileOperationError, Exception)

    def test_json_decode_error_is_file_operation_error(self) -> None:
        """Test that JSONDecodeError inherits from FileOperationError."""
        assert issubclass(JSONDecodeError, FileOperationError)

    def test_yaml_decode_error_is_file_operation_error(self) -> None:
        """Test that YAMLDecodeError inherits from FileOperationError."""
        assert issubclass(YAMLDecodeError, FileOperationError)

    def test_json_decode_error_message(self, temp_dir: pathlib.Path) -> None:
        """Test that JSONDecodeError has informative message."""
        test_file = File(temp_dir / "bad.json")
        test_file.write_text("{bad json")

        with pytest.raises(JSONDecodeError) as exc_info:
            test_file.load_json()

        error_msg = str(exc_info.value)
        assert "Failed to decode JSON" in error_msg
        assert str(test_file) in error_msg

    def test_yaml_decode_error_message(self, temp_dir: pathlib.Path) -> None:
        """Test that YAMLDecodeError has informative message."""
        test_file = File(temp_dir / "bad.yaml")
        test_file.write_text("invalid: [yaml")

        with pytest.raises(YAMLDecodeError) as exc_info:
            test_file.load_yaml()

        error_msg = str(exc_info.value)
        assert "Failed to decode YAML" in error_msg
        assert str(test_file) in error_msg


class TestAtomicWrite:
    """Test atomic write functionality."""

    def test_atomic_write_success(self, temp_dir: pathlib.Path) -> None:
        """Test successful atomic write."""
        test_file = File(temp_dir / "atomic.txt")

        with test_file.atomic_write() as f:
            f.write("Atomic content")

        assert test_file.exists()
        assert test_file.read_text() == "Atomic content"

    def test_atomic_write_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that atomic_write creates parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "atomic.txt")

        with test_file.atomic_write() as f:
            f.write("Nested content")

        assert test_file.exists()
        assert test_file.read_text() == "Nested content"

    def test_atomic_write_error_cleanup(self, temp_dir: pathlib.Path) -> None:
        """Test that atomic_write cleans up on error."""
        test_file = File(temp_dir / "atomic.txt")

        with pytest.raises(ValueError), test_file.atomic_write() as f:
            f.write("Partial content")
            raise ValueError("Simulated error")

        # File should not exist after error
        assert not test_file.exists()

    def test_atomic_write_binary_mode(self, temp_dir: pathlib.Path) -> None:
        """Test atomic_write in binary mode."""
        test_file = File(temp_dir / "atomic.bin")

        with test_file.atomic_write(mode="wb") as f:
            f.write(b"\x00\x01\x02\x03")

        assert test_file.exists()
        assert test_file.read_bytes() == b"\x00\x01\x02\x03"

    def test_atomic_write_preserves_existing_on_error(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that atomic_write preserves existing file on error."""
        test_file = File(temp_dir / "atomic.txt")
        test_file.write_text("Original content")

        with pytest.raises(ValueError), test_file.atomic_write() as f:
            f.write("New content")
            raise ValueError("Simulated error")

        # Original content should be preserved
        assert test_file.read_text() == "Original content"


class TestAsyncMethods:
    """Test async file operations."""

    @pytest.mark.asyncio
    async def test_read_text_async(self, temp_dir: pathlib.Path) -> None:
        """Test async text reading."""
        test_file = File(temp_dir / "async.txt")
        test_file.write_text("Hello async!")

        content = await test_file.read_text_async()

        assert content == "Hello async!"

    @pytest.mark.asyncio
    async def test_write_text_async(self, temp_dir: pathlib.Path) -> None:
        """Test async text writing."""
        test_file = File(temp_dir / "async.txt")

        await test_file.write_text_async("Async content")

        assert test_file.read_text() == "Async content"

    @pytest.mark.asyncio
    async def test_load_json_async(self, temp_dir: pathlib.Path) -> None:
        """Test async JSON loading."""
        test_file = File(temp_dir / "async.json")
        test_file.dump_json({"name": "test", "value": 42})

        data = await test_file.load_json_async()

        assert data == {"name": "test", "value": 42}

    @pytest.mark.asyncio
    async def test_load_json_async_with_type(self, temp_dir: pathlib.Path) -> None:
        """Test async JSON loading with type."""
        test_file = File(temp_dir / "async.json")
        test_file.dump_json({"name": "Easy File", "version": "0.4.0", "debug": True})

        data = await test_file.load_json_async(Config)

        assert data["name"] == "Easy File"
        assert data["version"] == "0.4.0"
        assert data["debug"] is True

    @pytest.mark.asyncio
    async def test_dump_json_async(self, temp_dir: pathlib.Path) -> None:
        """Test async JSON dumping."""
        test_file = File(temp_dir / "async.json")

        await test_file.dump_json_async({"async": "data"})

        assert test_file.load_json() == {"async": "data"}

    @pytest.mark.asyncio
    async def test_load_yaml_async(self, temp_dir: pathlib.Path) -> None:
        """Test async YAML loading."""
        test_file = File(temp_dir / "async.yaml")
        test_file.dump_yaml({"port": 8080, "host": "localhost"})

        data = await test_file.load_yaml_async()

        assert data == {"port": 8080, "host": "localhost"}

    @pytest.mark.asyncio
    async def test_load_yaml_async_with_type(self, temp_dir: pathlib.Path) -> None:
        """Test async YAML loading with type."""
        test_file = File(temp_dir / "async.yaml")
        test_file.dump_yaml({"port": 8080, "host": "localhost", "enabled": True})

        data = await test_file.load_yaml_async(Settings)

        assert data["port"] == 8080
        assert data["host"] == "localhost"
        assert data["enabled"] is True

    @pytest.mark.asyncio
    async def test_dump_yaml_async(self, temp_dir: pathlib.Path) -> None:
        """Test async YAML dumping."""
        test_file = File(temp_dir / "async.yaml")

        await test_file.dump_yaml_async({"async": "yaml"})

        assert test_file.load_yaml() == {"async": "yaml"}

    @pytest.mark.asyncio
    async def test_read_text_async_encoding(self, temp_dir: pathlib.Path) -> None:
        """Test async text reading with custom encoding."""
        test_file = File(temp_dir / "async.txt")
        test_file.write_text("Привіт світ!", encoding="utf-8")

        content = await test_file.read_text_async(encoding="utf-8")

        assert content == "Привіт світ!"

    @pytest.mark.asyncio
    async def test_write_text_async_encoding(self, temp_dir: pathlib.Path) -> None:
        """Test async text writing with custom encoding."""
        test_file = File(temp_dir / "async.txt")

        await test_file.write_text_async("Привіт світ!", encoding="utf-8")

        assert test_file.read_text(encoding="utf-8") == "Привіт світ!"

    @pytest.mark.asyncio
    async def test_read_bytes_async(self, temp_dir: pathlib.Path) -> None:
        """Test async bytes reading."""
        test_file = File(temp_dir / "async.bin")
        test_file.write_bytes(b"\x00\x01\x02\x03\x04")

        content = await test_file.read_bytes_async()

        assert content == b"\x00\x01\x02\x03\x04"

    @pytest.mark.asyncio
    async def test_write_bytes_async(self, temp_dir: pathlib.Path) -> None:
        """Test async bytes writing."""
        test_file = File(temp_dir / "async.bin")

        await test_file.write_bytes_async(b"\x00\x01\x02\x03\x04")

        assert test_file.read_bytes() == b"\x00\x01\x02\x03\x04"

    @pytest.mark.asyncio
    async def test_read_write_bytes_async_roundtrip(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test async bytes read/write roundtrip."""
        test_file = File(temp_dir / "async.bin")
        original_data = b"\x00\x01\x02\x03\x04\x05\x06\x07\x08\x09"

        await test_file.write_bytes_async(original_data)
        read_data = await test_file.read_bytes_async()

        assert read_data == original_data

    @pytest.mark.asyncio
    async def test_read_bytes_async_empty_file(self, temp_dir: pathlib.Path) -> None:
        """Test async bytes reading from empty file."""
        test_file = File(temp_dir / "empty.bin")
        test_file.write_bytes(b"")

        content = await test_file.read_bytes_async()

        assert content == b""

    @pytest.mark.asyncio
    async def test_read_bytes_async_missing_file(self, temp_dir: pathlib.Path) -> None:
        """Test async bytes reading from missing file raises FileNotFoundError."""
        test_file = File(temp_dir / "missing.bin")

        with pytest.raises(FileNotFoundError):
            await test_file.read_bytes_async()

    @pytest.mark.asyncio
    async def test_write_bytes_async_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that write_bytes_async creates parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "async.bin")

        await test_file.write_bytes_async(b"\x00\x01\x02")

        assert test_file.exists()
        assert test_file.read_bytes() == b"\x00\x01\x02"

    @pytest.mark.asyncio
    async def test_append_text_async(self, temp_dir: pathlib.Path) -> None:
        """Test async appending text to existing file."""
        test_file = File(temp_dir / "append.txt")
        test_file.write_text("First line\n")

        await test_file.append_text_async("Second line\n")

        assert test_file.read_text() == "First line\nSecond line\n"

    @pytest.mark.asyncio
    async def test_append_text_async_creates_file(self, temp_dir: pathlib.Path) -> None:
        """Test that append_text_async creates file if it doesn't exist."""
        test_file = File(temp_dir / "new.txt")

        await test_file.append_text_async("Appended content")

        assert test_file.exists()
        assert test_file.read_text() == "Appended content"

    @pytest.mark.asyncio
    async def test_append_text_async_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that append_text_async creates parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "file.txt")

        await test_file.append_text_async("Nested append")

        assert test_file.exists()
        assert test_file.read_text() == "Nested append"

    @pytest.mark.asyncio
    async def test_append_text_async_multiple_times(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test multiple async appends to same file."""
        test_file = File(temp_dir / "multi.txt")

        await test_file.append_text_async("Line 1\n")
        await test_file.append_text_async("Line 2\n")
        await test_file.append_text_async("Line 3\n")

        assert test_file.read_text() == "Line 1\nLine 2\nLine 3\n"

    @pytest.mark.asyncio
    async def test_append_text_async_encoding(self, temp_dir: pathlib.Path) -> None:
        """Test async appending text with custom encoding."""
        test_file = File(temp_dir / "encoding.txt")
        test_file.write_text("Привіт ", encoding="utf-8")

        await test_file.append_text_async("світ!", encoding="utf-8")

        assert test_file.read_text(encoding="utf-8") == "Привіт світ!"

    @pytest.mark.asyncio
    async def test_move_async(self, temp_dir: pathlib.Path) -> None:
        """Test async moving a file."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("test content")
        moved = await source.move_async(target_path)

        assert moved.exists()
        assert moved.read_text() == "test content"
        assert not source.exists()

    @pytest.mark.asyncio
    async def test_move_async_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that async move creates parent directories if needed."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "nested" / "deep" / "target.txt"

        source.write_text("test content")
        moved = await source.move_async(target_path)

        assert moved.exists()
        assert moved.read_text() == "test content"
        assert not source.exists()

    @pytest.mark.asyncio
    async def test_move_async_source_deleted(self, temp_dir: pathlib.Path) -> None:
        """Test that source file is deleted after async move."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("content to move")
        await source.move_async(target_path)

        assert not source.exists()
        assert File(target_path).exists()

    @pytest.mark.asyncio
    async def test_copy_async(self, temp_dir: pathlib.Path) -> None:
        """Test async copying a file."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        source.write_text("test content")
        copied = await source.copy_async(target_path)

        assert copied.exists()
        assert copied.read_text() == "test content"
        assert source.exists()
        assert source.read_text() == "test content"

    @pytest.mark.asyncio
    async def test_copy_async_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that async copy creates parent directories if needed."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "nested" / "deep" / "target.txt"

        source.write_text("test content")
        copied = await source.copy_async(target_path)

        assert copied.exists()
        assert copied.read_text() == "test content"
        assert source.exists()

    @pytest.mark.asyncio
    async def test_copy_async_binary_file(self, temp_dir: pathlib.Path) -> None:
        """Test async copying a binary file."""
        source = File(temp_dir / "source.bin")
        target_path = temp_dir / "target.bin"

        source.write_bytes(b"\x00\x01\x02\x03\x04\x05")
        copied = await source.copy_async(target_path)

        assert copied.exists()
        assert copied.read_bytes() == b"\x00\x01\x02\x03\x04\x05"
        assert source.exists()
        assert source.read_bytes() == b"\x00\x01\x02\x03\x04\x05"

    @pytest.mark.asyncio
    async def test_copy_async_source_preserved(self, temp_dir: pathlib.Path) -> None:
        """Test that source file is preserved after async copy."""
        source = File(temp_dir / "source.txt")
        target_path = temp_dir / "target.txt"

        original_content = "Original content that should be preserved"
        source.write_text(original_content)
        copied = await source.copy_async(target_path)

        # Verify source still exists and has original content
        assert source.exists()
        assert source.read_text() == original_content

        # Verify copy was created correctly
        assert copied.exists()
        assert copied.read_text() == original_content


class TestUtilityMethods:
    """Test utility methods."""

    def test_append_text(self, temp_dir: pathlib.Path) -> None:
        """Test appending text to file."""
        test_file = File(temp_dir / "append.txt")
        test_file.write_text("First line\n")

        test_file.append_text("Second line\n")

        assert test_file.read_text() == "First line\nSecond line\n"

    def test_append_text_creates_file(self, temp_dir: pathlib.Path) -> None:
        """Test that append_text creates file if it doesn't exist."""
        test_file = File(temp_dir / "new.txt")

        test_file.append_text("Appended content")

        assert test_file.exists()
        assert test_file.read_text() == "Appended content"

    def test_append_text_creates_parent_directories(
        self, temp_dir: pathlib.Path
    ) -> None:
        """Test that append_text creates parent directories."""
        test_file = File(temp_dir / "nested" / "file.txt")

        test_file.append_text("Nested append")

        assert test_file.exists()
        assert test_file.read_text() == "Nested append"

    def test_append_text_multiple_times(self, temp_dir: pathlib.Path) -> None:
        """Test multiple appends to same file."""
        test_file = File(temp_dir / "multi.txt")

        test_file.append_text("Line 1\n")
        test_file.append_text("Line 2\n")
        test_file.append_text("Line 3\n")

        assert test_file.read_text() == "Line 1\nLine 2\nLine 3\n"

    def test_touch_parents(self, temp_dir: pathlib.Path) -> None:
        """Test touch_parents creates file and parent directories."""
        test_file = File(temp_dir / "nested" / "deep" / "file.txt")

        test_file.touch_parents()

        assert test_file.exists()
        assert test_file.is_file()

    def test_touch_parents_existing_file(self, temp_dir: pathlib.Path) -> None:
        """Test touch_parents with existing file."""
        test_file = File(temp_dir / "existing.txt")
        test_file.write_text("Content")

        test_file.touch_parents()

        assert test_file.exists()
        assert test_file.read_text() == "Content"

    def test_size_property(self, temp_dir: pathlib.Path) -> None:
        """Test size property returns correct file size."""
        test_file = File(temp_dir / "size.txt")
        test_file.write_text("Hello")

        assert test_file.size == 5

    def test_size_property_empty_file(self, temp_dir: pathlib.Path) -> None:
        """Test size property for empty file."""
        test_file = File(temp_dir / "empty.txt")
        test_file.write_text("")

        assert test_file.size == 0

    def test_size_property_binary_file(self, temp_dir: pathlib.Path) -> None:
        """Test size property for binary file."""
        test_file = File(temp_dir / "binary.bin")
        test_file.write_bytes(b"\x00\x01\x02\x03\x04")

        assert test_file.size == 5

    def test_size_property_missing_file(self, temp_dir: pathlib.Path) -> None:
        """Test size property raises FileNotFoundError for missing file."""
        test_file = File(temp_dir / "missing.txt")

        with pytest.raises(FileNotFoundError):
            _ = test_file.size

    def test_size_property_unicode_content(self, temp_dir: pathlib.Path) -> None:
        """Test size property with Unicode content."""
        test_file = File(temp_dir / "unicode.txt")
        test_file.write_text("Привіт світ!")

        # Verify the file size is correct for UTF-8 encoding
        # The actual size depends on how Python encodes the text
        # Just verify that the size is non-zero and matches the content length
        assert test_file.size > 0
        # Read back and verify content matches
        assert test_file.read_text() == "Привіт світ!"


class TestFileInheritance:
    """Test that File properly inherits from pathlib.Path."""

    def test_file_is_path_instance(self, temp_dir: pathlib.Path) -> None:
        """Test that File is an instance of pathlib.Path."""
        test_file = File(temp_dir / "test.txt")
        assert isinstance(test_file, pathlib.Path)

    def test_path_methods_work(self, temp_dir: pathlib.Path) -> None:
        """Test that standard pathlib methods work."""
        test_file = File(temp_dir / "subdir" / "test.txt")

        assert test_file.name == "test.txt"
        assert test_file.stem == "test"
        assert test_file.suffix == ".txt"
        assert "subdir" in str(test_file)

    def test_file_can_be_used_as_path(self, temp_dir: pathlib.Path) -> None:
        """Test that File can be used where Path is expected."""
        test_file = File(temp_dir / "test.txt")
        test_file.write_text("content")

        # Should work with pathlib operations
        parent = test_file.parent
        assert parent.exists()

        # Should work with Path operations
        assert test_file.with_suffix(".bak") == File(temp_dir / "test.bak")


class TestEdgeCases:
    """Test edge cases and boundary conditions."""

    def test_empty_json(self, temp_dir: pathlib.Path) -> None:
        """Test loading empty JSON object."""
        test_file = File(temp_dir / "empty.json")
        test_file.dump_json({})

        loaded = test_file.load_json()
        assert loaded == {}

    def test_empty_yaml(self, temp_dir: pathlib.Path) -> None:
        """Test loading empty YAML."""
        test_file = File(temp_dir / "empty.yaml")
        test_file.dump_yaml({})

        loaded = test_file.load_yaml()
        assert loaded == {}

    def test_large_json(self, temp_dir: pathlib.Path) -> None:
        """Test loading large JSON file."""
        test_file = File(temp_dir / "large.json")
        large_data = {"items": [{"id": i, "value": f"item_{i}"} for i in range(1000)]}
        test_file.dump_json(large_data)

        loaded = test_file.load_json()
        assert len(loaded["items"]) == 1000

    def test_nested_json(self, temp_dir: pathlib.Path) -> None:
        """Test loading deeply nested JSON."""
        test_file = File(temp_dir / "nested.json")
        nested_data = {"level1": {"level2": {"level3": {"level4": "deep"}}}}
        test_file.dump_json(nested_data)

        loaded = test_file.load_json()
        assert loaded["level1"]["level2"]["level3"]["level4"] == "deep"

    def test_special_characters_in_json(self, temp_dir: pathlib.Path) -> None:
        """Test JSON with special characters."""
        test_file = File(temp_dir / "special.json")
        special_data = {
            "unicode": "Привіт 世界 🌍",
            "quotes": 'He said "Hello"',
            "newlines": "Line1\nLine2",
            "tabs": "Col1\tCol2",
        }
        test_file.dump_json(special_data)

        loaded = test_file.load_json()
        assert loaded["unicode"] == "Привіт 世界 🌍"
        assert loaded["quotes"] == 'He said "Hello"'
        assert loaded["newlines"] == "Line1\nLine2"
        assert loaded["tabs"] == "Col1\tCol2"

    def test_yaml_multiline_strings(self, temp_dir: pathlib.Path) -> None:
        """Test YAML with multiline strings."""
        test_file = File(temp_dir / "multiline.yaml")
        multiline_data = {"description": "This is a\nmultiline\nstring"}
        test_file.dump_yaml(multiline_data)

        loaded = test_file.load_yaml()
        assert loaded["description"] == "This is a\nmultiline\nstring"

    def test_json_list(self, temp_dir: pathlib.Path) -> None:
        """Test loading JSON array."""
        test_file = File(temp_dir / "list.json")
        list_data = [1, 2, 3, "four", {"five": 5}]
        test_file.dump_json(list_data)

        loaded = test_file.load_json()
        assert loaded == [1, 2, 3, "four", {"five": 5}]

    def test_yaml_list(self, temp_dir: pathlib.Path) -> None:
        """Test loading YAML list."""
        test_file = File(temp_dir / "list.yaml")
        list_data = [1, 2, 3, "four", {"five": 5}]
        test_file.dump_yaml(list_data)

        loaded = test_file.load_yaml()
        assert loaded == [1, 2, 3, "four", {"five": 5}]

    def test_json_null_values(self, temp_dir: pathlib.Path) -> None:
        """Test JSON with null values."""
        test_file = File(temp_dir / "null.json")
        null_data = {"value": None, "list": [1, None, 3]}
        test_file.dump_json(null_data)

        loaded = test_file.load_json()
        assert loaded["value"] is None
        assert loaded["list"][1] is None

    def test_yaml_null_values(self, temp_dir: pathlib.Path) -> None:
        """Test YAML with null values."""
        test_file = File(temp_dir / "null.yaml")
        null_data = {"value": None, "list": [1, None, 3]}
        test_file.dump_yaml(null_data)

        loaded = test_file.load_yaml()
        assert loaded["value"] is None
        assert loaded["list"][1] is None

    def test_json_boolean_values(self, temp_dir: pathlib.Path) -> None:
        """Test JSON with boolean values."""
        test_file = File(temp_dir / "bool.json")
        bool_data = {"true_val": True, "false_val": False}
        test_file.dump_json(bool_data)

        loaded = test_file.load_json()
        assert loaded["true_val"] is True
        assert loaded["false_val"] is False

    def test_yaml_boolean_values(self, temp_dir: pathlib.Path) -> None:
        """Test YAML with boolean values."""
        test_file = File(temp_dir / "bool.yaml")
        bool_data = {"true_val": True, "false_val": False}
        test_file.dump_yaml(bool_data)

        loaded = test_file.load_yaml()
        assert loaded["true_val"] is True
        assert loaded["false_val"] is False

    def test_numeric_values_json(self, temp_dir: pathlib.Path) -> None:
        """Test JSON with various numeric types."""
        test_file = File(temp_dir / "numeric.json")
        numeric_data = {
            "int": 42,
            "float": 3.14,
            "negative": -10,
            "zero": 0,
            "large": 1000000,
        }
        test_file.dump_json(numeric_data)

        loaded = test_file.load_json()
        assert loaded["int"] == 42
        assert loaded["float"] == 3.14
        assert loaded["negative"] == -10
        assert loaded["zero"] == 0
        assert loaded["large"] == 1000000

    def test_numeric_values_yaml(self, temp_dir: pathlib.Path) -> None:
        """Test YAML with various numeric types."""
        test_file = File(temp_dir / "numeric.yaml")
        numeric_data = {
            "int": 42,
            "float": 3.14,
            "negative": -10,
            "zero": 0,
            "large": 1000000,
        }
        test_file.dump_yaml(numeric_data)

        loaded = test_file.load_yaml()
        assert loaded["int"] == 42
        assert loaded["float"] == 3.14
        assert loaded["negative"] == -10
        assert loaded["zero"] == 0
        assert loaded["large"] == 1000000

```

